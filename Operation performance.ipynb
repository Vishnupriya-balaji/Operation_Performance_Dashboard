{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-13T15:42:24.826995Z",
     "start_time": "2025-11-13T15:42:24.402934Z"
    }
   },
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(r\"C:\\Users\\bvish\\PyCharmMiscProject\\Data\\Customer_support_tickets.csv\")\n",
    "\n",
    "# Convert dates\n",
    "df['First Response Time'] = pd.to_datetime(df['First Response Time'], errors='coerce')\n",
    "df['Time to Resolution'] = pd.to_datetime(df['Time to Resolution'], errors='coerce')\n",
    "\n",
    "# Create Resolution_Time in days\n",
    "df['Resolution_Time'] = (df['Time to Resolution'] - df['First Response Time']).dt.days\n",
    "\n",
    "# Fill missing values\n",
    "df['Resolution_Time'] = df['Resolution_Time'].fillna(0)\n",
    "\n",
    "# Add realistic fields (optional synthetic enrichment)\n",
    "import random\n",
    "df['Priority'] = np.random.choice(['Low', 'Medium', 'High', 'Critical'], len(df))\n",
    "df['Issue_Type'] = np.random.choice(['Billing', 'Technical Issue', 'Account', 'Product Bug'], len(df))\n",
    "df['Customer_Satisfaction'] = np.random.randint(1,6, len(df))\n",
    "df['Channel'] = np.random.choice(['Email', 'Chat', 'Phone', 'Web Form'], len(df))\n",
    "df['Reopen_Count'] = np.random.randint(0,4, len(df))\n",
    "\n",
    "# Export cleaned data\n",
    "df.to_csv(\"Customer_Support_tickets.csv\", index=False)\n"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T15:40:18.758041Z",
     "start_time": "2025-11-13T15:40:18.706533Z"
    }
   },
   "cell_type": "code",
   "source": "df.columns",
   "id": "2728941900bbf983",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Ticket ID', 'Customer_ID', 'Customer Name', 'Customer Email',\n",
       "       'Customer Age', 'Customer Gender', 'Product Purchased',\n",
       "       'Date of Purchase', 'Ticket Type', 'Ticket Subject',\n",
       "       'Ticket Description', 'Ticket Status', 'Resolution', 'Ticket Priority',\n",
       "       'Ticket Channel', 'Agent', 'Region', 'Product_Module',\n",
       "       'First Response Time', 'Time to Resolution',\n",
       "       'Customer Satisfaction Rating'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T15:49:08.524150Z",
     "start_time": "2025-11-13T15:49:07.912207Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv(r\"C:\\Users\\bvish\\PycharmProjects\\Customer_support_tickets\\Customer_support_tickets.csv\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# STEP 1: Clean column names (strip spaces and unify case)\n",
    "# ------------------------------------------------------------\n",
    "df.columns = df.columns.str.strip().str.replace(\" \", \"_\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# STEP 2: Rename Date columns\n",
    "# ------------------------------------------------------------\n",
    "rename_map = {\n",
    "    'Date_Opened': 'First_Response_Time',\n",
    "    'Date_Closed': 'Time_to_Resolution'\n",
    "}\n",
    "df.rename(columns=rename_map, inplace=True)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# STEP 3: Convert date columns and handle nulls\n",
    "# ------------------------------------------------------------\n",
    "if 'First_Response_Time' in df.columns:\n",
    "    df['First_Response_Time'] = pd.to_datetime(df['First_Response_Time'], errors='coerce')\n",
    "    df['First_Response_Time'] = df['First_Response_Time'].fillna(df['First_Response_Time'].min())\n",
    "\n",
    "if 'Time_to_Resolution' in df.columns:\n",
    "    df['Time_to_Resolution'] = pd.to_datetime(df['Time_to_Resolution'], errors='coerce')\n",
    "    # Fill missing Time_to_Resolution as 1 day after First_Response_Time\n",
    "    df['Time_to_Resolution'] = df['Time_to_Resolution'].fillna(\n",
    "        df['First_Response_Time'] + pd.Timedelta(days=1)\n",
    "    )\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# STEP 4: Handle other missing values\n",
    "# ------------------------------------------------------------\n",
    "categorical_cols = ['Agent', 'Region', 'Product_Module', 'Status', 'Priority', 'Issue_Type', 'Channel']\n",
    "for col in categorical_cols:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].fillna(df[col].mode()[0])\n",
    "\n",
    "numeric_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "for col in numeric_cols:\n",
    "    df[col] = df[col].fillna(df[col].mean())\n",
    "\n",
    "if 'Feedback_Comment' in df.columns:\n",
    "    df['Feedback_Comment'] = df['Feedback_Comment'].fillna(\"No feedback provided\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# STEP 5: Verify cleaning\n",
    "# ------------------------------------------------------------\n",
    "print(\"Null values remaining:\\n\", df.isnull().sum())\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# STEP 6: Export cleaned dataset\n",
    "# ------------------------------------------------------------\n",
    "output_path = r\"C:\\Users\\bvish\\PycharmProjects\\Customer_support_tickets\\cleaned_tickets.csv\"\n",
    "df.to_csv(output_path, index=False)\n",
    "print(f\"\\n✅ Cleaned dataset saved successfully at:\\n{output_path}\")\n"
   ],
   "id": "7cf26022119fa2a1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null values remaining:\n",
      " Ticket_ID                          0\n",
      "Customer_ID                        0\n",
      "Customer_Name                      0\n",
      "Customer_Email                     0\n",
      "Customer_Age                       0\n",
      "Customer_Gender                    0\n",
      "Product_Purchased                  0\n",
      "Date_of_Purchase                   0\n",
      "Ticket_Type                        0\n",
      "Ticket_Subject                     0\n",
      "Ticket_Description                 0\n",
      "Ticket_Status                      0\n",
      "Resolution                      5700\n",
      "Ticket_Priority                    0\n",
      "Ticket_Channel                     0\n",
      "Agent                              0\n",
      "Region                             0\n",
      "Product_Module                     0\n",
      "First_Response_Time                0\n",
      "Time_to_Resolution                 0\n",
      "Customer_Satisfaction_Rating       0\n",
      "Resolution_Time                    0\n",
      "Priority                           0\n",
      "Issue_Type                         0\n",
      "Customer_Satisfaction              0\n",
      "Channel                            0\n",
      "Reopen_Count                       0\n",
      "dtype: int64\n",
      "\n",
      "✅ Cleaned dataset saved successfully at:\n",
      "C:\\Users\\bvish\\PycharmProjects\\Customer_support_tickets\\cleaned_tickets.csv\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T02:35:07.379022Z",
     "start_time": "2025-11-14T02:35:05.321884Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv(r\"C:\\Users\\bvish\\PycharmProjects\\Customer_support_tickets\\Customer_Support_tickets.csv\")\n",
    "\n",
    "# Clean headers\n",
    "df.columns = df.columns.str.strip().str.replace(\" \", \"_\").str.replace(\"-\", \"_\")\n",
    "\n",
    "# Save cleaned version\n",
    "df.to_csv(r\"C:\\Users\\bvish\\PycharmProjects\\Customer_support_tickets\\Customer_Support_tickets_cleaned.csv\", index=False)\n",
    "\n",
    "print(\"✅ Clean CSV saved successfully.\")\n"
   ],
   "id": "88179fced8e47514",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Clean CSV saved successfully.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-16T10:53:47.610194Z",
     "start_time": "2025-11-16T10:53:47.273897Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import mysql.connector\n",
    "\n",
    "# ---------- LOAD CSV ----------\n",
    "df = pd.read_csv(r\"C:\\Users\\bvish\\PyCharmMiscProject\\Data\\Customer_Support_tickets_cleaned.csv\")\n",
    "\n",
    "# ---------- MYSQL CONNECTION ----------\n",
    "conn = mysql.connector.connect(\n",
    "    host=\"localhost\",\n",
    "    user=\"root\",\n",
    "    password=\"Vishpri@1104\",\n",
    "    database=\"support_ticket\"\n",
    ")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# ---------- TABLE NAME ----------\n",
    "table_name = \"tickets\"\n",
    "\n",
    "# ---------- SCHEMA DEFINITION (STRICT TYPES) ----------\n",
    "schema = {\n",
    "    \"Ticket_ID\": \"INT PRIMARY KEY\",\n",
    "    \"Customer_ID\": \"VARCHAR(20)\",\n",
    "    \"Customer_Name\": \"VARCHAR(100)\",\n",
    "    \"Customer_Email\": \"VARCHAR(150)\",\n",
    "    \"Customer_Age\": \"INT\",\n",
    "    \"Customer_Gender\": \"ENUM('Male','Female','Other')\",\n",
    "    \"Product_Purchased\": \"VARCHAR(100)\",\n",
    "    \"Date_of_Purchase\": \"DATE\",\n",
    "    \"Ticket_Type\": \"VARCHAR(50)\",\n",
    "    \"Ticket_Subject\": \"VARCHAR(255)\",\n",
    "    \"Ticket_Description\": \"TEXT\",\n",
    "    \"Date_Created\": \"DATE\",\n",
    "    \"Date_Closed\": \"DATE\",\n",
    "    \"Ticket_Status\": \"VARCHAR(50)\",\n",
    "    \"Resolution\": \"TEXT\",\n",
    "    \"Ticket_Priority\": \"VARCHAR(50)\",\n",
    "    \"Ticket_Channel\": \"VARCHAR(50)\",\n",
    "    \"Agent\": \"VARCHAR(100)\",\n",
    "    \"Region\": \"VARCHAR(100)\",\n",
    "    \"Product_Module\": \"VARCHAR(100)\",\n",
    "    \"First_Response_Time\": \"INT\",\n",
    "    \"Time_to_Resolution\": \"INT\",\n",
    "    \"Customer_Satisfaction_Rating\": \"INT\",\n",
    "    \"Resolution_Time\": \"INT\",\n",
    "    \"Priority\": \"VARCHAR(50)\",\n",
    "    \"Issue_Type\": \"VARCHAR(100)\",\n",
    "    \"Customer_Satisfaction\": \"INT\",\n",
    "    \"Channel\": \"VARCHAR(50)\",\n",
    "    \"Reopen_Count\": \"INT\"\n",
    "}\n",
    "\n",
    "# ---------- AUTO CREATE TABLE ----------\n",
    "columns_sql = \",\\n    \".join([f\"{col} {datatype}\" for col, datatype in schema.items()])\n",
    "create_table_sql = f\"CREATE TABLE IF NOT EXISTS {table_name} (\\n    {columns_sql}\\n);\"\n",
    "\n",
    "cursor.execute(create_table_sql)\n",
    "print(\"Table created (or already exists).\")\n",
    "\n",
    "# ---------- PREPARE BULK INSERT ----------\n",
    "placeholders = \", \".join([\"%s\"] * len(schema.keys()))\n",
    "columns = \", \".join(schema.keys())\n",
    "\n",
    "insert_sql = f\"INSERT INTO {table_name} ({columns}) VALUES ({placeholders})\"\n",
    "\n",
    "# Convert DataFrame rows → tuples\n",
    "actual_columns = [c for c in schema.keys() if c in df.columns]\n",
    "df = df[actual_columns]\n",
    "\n",
    "records = [tuple(x if pd.notna(x) else None for x in row) for row in df.to_numpy()]\n",
    "\n",
    "# ---------- BULK INSERT ----------\n",
    "cursor.executemany(insert_sql, records)\n",
    "conn.commit()\n",
    "\n",
    "print(f\"{cursor.rowcount} rows inserted successfully.\")\n",
    "\n",
    "cursor.close()\n",
    "conn.close()\n"
   ],
   "id": "6e119d2415e6294c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table created (or already exists).\n"
     ]
    },
    {
     "ename": "InterfaceError",
     "evalue": "Failed executing the operation; Not enough parameters for the SQL statement",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mInterfaceError\u001B[39m                            Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[6]\u001B[39m\u001B[32m, line 72\u001B[39m\n\u001B[32m     69\u001B[39m records = [\u001B[38;5;28mtuple\u001B[39m(x \u001B[38;5;28;01mif\u001B[39;00m pd.notna(x) \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m row) \u001B[38;5;28;01mfor\u001B[39;00m row \u001B[38;5;129;01min\u001B[39;00m df.to_numpy()]\n\u001B[32m     71\u001B[39m \u001B[38;5;66;03m# ---------- BULK INSERT ----------\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m72\u001B[39m \u001B[43mcursor\u001B[49m\u001B[43m.\u001B[49m\u001B[43mexecutemany\u001B[49m\u001B[43m(\u001B[49m\u001B[43minsert_sql\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrecords\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     73\u001B[39m conn.commit()\n\u001B[32m     75\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mcursor.rowcount\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m rows inserted successfully.\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\Customer_support_tickets\\.venv\\Lib\\site-packages\\mysql\\connector\\cursor_cext.py:470\u001B[39m, in \u001B[36mCMySQLCursor.executemany\u001B[39m\u001B[34m(self, operation, seq_params)\u001B[39m\n\u001B[32m    468\u001B[39m     \u001B[38;5;28mself\u001B[39m._rowcount = \u001B[32m0\u001B[39m\n\u001B[32m    469\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m470\u001B[39m stmt = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_batch_insert\u001B[49m\u001B[43m(\u001B[49m\u001B[43moperation\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mseq_params\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    471\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m stmt \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    472\u001B[39m     \u001B[38;5;28mself\u001B[39m._executed = stmt\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\Customer_support_tickets\\.venv\\Lib\\site-packages\\mysql\\connector\\cursor_cext.py:424\u001B[39m, in \u001B[36mCMySQLCursor._batch_insert\u001B[39m\u001B[34m(self, operation, seq_params)\u001B[39m\n\u001B[32m    422\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m ProgrammingError(\u001B[38;5;28mstr\u001B[39m(err)) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01merr\u001B[39;00m\n\u001B[32m    423\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[32m--> \u001B[39m\u001B[32m424\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m InterfaceError(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mFailed executing the operation; \u001B[39m\u001B[38;5;132;01m{\u001B[39;00merr\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[31mInterfaceError\u001B[39m: Failed executing the operation; Not enough parameters for the SQL statement"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-16T10:55:22.225919Z",
     "start_time": "2025-11-16T10:55:22.217233Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"DF Columns:\", df.columns.tolist())\n",
    "print(\"Schema Keys:\", list(schema.keys()))\n",
    "print(\"Actual columns used:\", actual_columns)\n",
    "print(\"INSERT SQL:\", insert_sql)\n",
    "print(\"Example record:\", records[0])\n",
    "print(\"Number of placeholders:\", insert_sql.count(\"%s\"))\n",
    "print(\"Number of values in record:\", len(records[0]))\n"
   ],
   "id": "86299cc9f1c23a16",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DF Columns: ['Ticket_ID', 'Customer_ID', 'Customer_Name', 'Customer_Email', 'Customer_Age', 'Customer_Gender', 'Product_Purchased', 'Date_of_Purchase', 'Ticket_Type', 'Ticket_Subject', 'Ticket_Description', 'Ticket_Status', 'Resolution', 'Ticket_Priority', 'Ticket_Channel', 'Agent', 'Region', 'Product_Module', 'First_Response_Time', 'Time_to_Resolution', 'Customer_Satisfaction_Rating', 'Resolution_Time', 'Priority', 'Issue_Type', 'Customer_Satisfaction', 'Channel', 'Reopen_Count']\n",
      "Schema Keys: ['Ticket_ID', 'Customer_ID', 'Customer_Name', 'Customer_Email', 'Customer_Age', 'Customer_Gender', 'Product_Purchased', 'Date_of_Purchase', 'Ticket_Type', 'Ticket_Subject', 'Ticket_Description', 'Date_Created', 'Date_Closed', 'Ticket_Status', 'Resolution', 'Ticket_Priority', 'Ticket_Channel', 'Agent', 'Region', 'Product_Module', 'First_Response_Time', 'Time_to_Resolution', 'Customer_Satisfaction_Rating', 'Resolution_Time', 'Priority', 'Issue_Type', 'Customer_Satisfaction', 'Channel', 'Reopen_Count']\n",
      "Actual columns used: ['Ticket_ID', 'Customer_ID', 'Customer_Name', 'Customer_Email', 'Customer_Age', 'Customer_Gender', 'Product_Purchased', 'Date_of_Purchase', 'Ticket_Type', 'Ticket_Subject', 'Ticket_Description', 'Ticket_Status', 'Resolution', 'Ticket_Priority', 'Ticket_Channel', 'Agent', 'Region', 'Product_Module', 'First_Response_Time', 'Time_to_Resolution', 'Customer_Satisfaction_Rating', 'Resolution_Time', 'Priority', 'Issue_Type', 'Customer_Satisfaction', 'Channel', 'Reopen_Count']\n",
      "INSERT SQL: INSERT INTO tickets (Ticket_ID, Customer_ID, Customer_Name, Customer_Email, Customer_Age, Customer_Gender, Product_Purchased, Date_of_Purchase, Ticket_Type, Ticket_Subject, Ticket_Description, Date_Created, Date_Closed, Ticket_Status, Resolution, Ticket_Priority, Ticket_Channel, Agent, Region, Product_Module, First_Response_Time, Time_to_Resolution, Customer_Satisfaction_Rating, Resolution_Time, Priority, Issue_Type, Customer_Satisfaction, Channel, Reopen_Count) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
      "Example record: (1, 'CUST1000', 'Marisa Obrien', 'carrollallison@example.com', 32, 'Other', 'GoPro Hero', '22-03-2021', 'Technical issue', 'Product setup', \"I'm having an issue with the {product_purchased}. Please assist.\\n\\nYour billing zip code is: 71701.\\n\\nWe appreciate that you have requested a website address.\\n\\nPlease double check your email address. I've tried troubleshooting steps mentioned in the user manual, but the issue persists.\", 'Pending Customer Response', None, 'Critical', 'Social media', 'Alex Johnson', 'Europe', 'Cameras', '06-01-2023 12:15', None, None, 0, 'Critical', 'Product Bug', 4, 'Email', 1)\n",
      "Number of placeholders: 29\n",
      "Number of values in record: 27\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-16T10:56:23.363910Z",
     "start_time": "2025-11-16T10:56:23.357117Z"
    }
   },
   "cell_type": "code",
   "source": [
    "schema = {\n",
    "    \"Ticket_ID\": \"INT\",\n",
    "    \"Customer_ID\": \"VARCHAR(50)\",\n",
    "    \"Customer_Name\": \"VARCHAR(255)\",\n",
    "    \"Customer_Email\": \"VARCHAR(255)\",\n",
    "    \"Customer_Age\": \"INT\",\n",
    "    \"Customer_Gender\": \"VARCHAR(50)\",\n",
    "    \"Product_Purchased\": \"VARCHAR(255)\",\n",
    "    \"Date_of_Purchase\": \"VARCHAR(50)\",\n",
    "    \"Ticket_Type\": \"VARCHAR(255)\",\n",
    "    \"Ticket_Subject\": \"VARCHAR(255)\",\n",
    "    \"Ticket_Description\": \"TEXT\",\n",
    "    \"Ticket_Status\": \"VARCHAR(100)\",\n",
    "    \"Resolution\": \"TEXT\",\n",
    "    \"Ticket_Priority\": \"VARCHAR(50)\",\n",
    "    \"Ticket_Channel\": \"VARCHAR(50)\",\n",
    "    \"Agent\": \"VARCHAR(100)\",\n",
    "    \"Region\": \"VARCHAR(100)\",\n",
    "    \"Product_Module\": \"VARCHAR(100)\",\n",
    "    \"First_Response_Time\": \"VARCHAR(50)\",\n",
    "    \"Time_to_Resolution\": \"VARCHAR(50)\",\n",
    "    \"Customer_Satisfaction_Rating\": \"INT\",\n",
    "    \"Resolution_Time\": \"VARCHAR(50)\",\n",
    "    \"Priority\": \"VARCHAR(50)\",\n",
    "    \"Issue_Type\": \"VARCHAR(100)\",\n",
    "    \"Customer_Satisfaction\": \"INT\",\n",
    "    \"Channel\": \"VARCHAR(100)\",\n",
    "    \"Reopen_Count\": \"INT\"\n",
    "}\n"
   ],
   "id": "91f6487fe31716ed",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-16T10:56:34.766665Z",
     "start_time": "2025-11-16T10:56:34.668203Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# pick only columns that exist in CSV\n",
    "actual_columns = [c for c in schema.keys() if c in df.columns]\n",
    "\n",
    "# build SQL INSERT\n",
    "columns = \", \".join(actual_columns)\n",
    "placeholders = \", \".join([\"%s\"] * len(actual_columns))\n",
    "insert_sql = f\"INSERT INTO tickets ({columns}) VALUES ({placeholders})\"\n",
    "\n",
    "# convert rows\n",
    "df = df[actual_columns]\n",
    "records = [tuple(None if pd.isna(x) else x for x in row) for row in df.to_numpy()]\n"
   ],
   "id": "8ea92b02fc08dde9",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-16T10:59:18.045498Z",
     "start_time": "2025-11-16T10:59:17.127387Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import mysql.connector\n",
    "\n",
    "# ---------- LOAD CSV ----------\n",
    "df = pd.read_csv(r\"C:\\Users\\bvish\\PyCharmMiscProject\\Data\\Customer_Support_tickets_cleaned.csv\")\n",
    "\n",
    "# ---------- MYSQL CONNECTION ----------\n",
    "conn = mysql.connector.connect(\n",
    "    host=\"localhost\",\n",
    "    user=\"root\",\n",
    "    password=\"Vishpri@1104\",\n",
    "    database=\"support_ticket\"\n",
    ")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# ---------- DEFINE SCHEMA BASED ON CSV ----------\n",
    "schema = {\n",
    "    \"Ticket_ID\": \"INT\",\n",
    "    \"Customer_ID\": \"VARCHAR(50)\",\n",
    "    \"Customer_Name\": \"VARCHAR(255)\",\n",
    "    \"Customer_Email\": \"VARCHAR(255)\",\n",
    "    \"Customer_Age\": \"INT\",\n",
    "    \"Customer_Gender\": \"VARCHAR(50)\",\n",
    "    \"Product_Purchased\": \"VARCHAR(255)\",\n",
    "    \"Date_of_Purchase\": \"VARCHAR(50)\",\n",
    "    \"Ticket_Type\": \"VARCHAR(255)\",\n",
    "    \"Ticket_Subject\": \"VARCHAR(255)\",\n",
    "    \"Ticket_Description\": \"TEXT\",\n",
    "    \"Ticket_Status\": \"VARCHAR(100)\",\n",
    "    \"Resolution\": \"TEXT\",\n",
    "    \"Ticket_Priority\": \"VARCHAR(50)\",\n",
    "    \"Ticket_Channel\": \"VARCHAR(50)\",\n",
    "    \"Agent\": \"VARCHAR(100)\",\n",
    "    \"Region\": \"VARCHAR(100)\",\n",
    "    \"Product_Module\": \"VARCHAR(100)\",\n",
    "    \"First_Response_Time\": \"VARCHAR(50)\",\n",
    "    \"Time_to_Resolution\": \"VARCHAR(50)\",\n",
    "    \"Customer_Satisfaction_Rating\": \"INT\",\n",
    "    \"Resolution_Time\": \"VARCHAR(50)\",\n",
    "    \"Priority\": \"VARCHAR(50)\",\n",
    "    \"Issue_Type\": \"VARCHAR(100)\",\n",
    "    \"Customer_Satisfaction\": \"INT\",\n",
    "    \"Channel\": \"VARCHAR(100)\",\n",
    "    \"Reopen_Count\": \"INT\"\n",
    "}\n",
    "\n",
    "table_name = \"Supporttickets\"\n",
    "\n",
    "# Keep only columns that exist in the CSV\n",
    "actual_columns = [col for col in schema.keys() if col in df.columns]\n",
    "df = df[actual_columns]\n",
    "\n",
    "# ---------- CREATE TABLE ----------\n",
    "create_sql = f\"CREATE TABLE IF NOT EXISTS {table_name} (\"\n",
    "for col in actual_columns:\n",
    "    create_sql += f\"{col} {schema[col]}, \"\n",
    "create_sql = create_sql.rstrip(\", \") + \")\"\n",
    "cursor.execute(create_sql)\n",
    "\n",
    "# ---------- PREPARE INSERT SQL ----------\n",
    "columns = \", \".join(actual_columns)\n",
    "placeholders = \", \".join([\"%s\"] * len(actual_columns))\n",
    "insert_sql = f\"INSERT INTO {table_name} ({columns}) VALUES ({placeholders})\"\n",
    "\n",
    "# ---------- CONVERT ROWS TO TUPLES ----------\n",
    "records = [tuple(None if pd.isna(x) else x for x in row) for row in df.to_numpy()]\n",
    "\n",
    "# ---------- BULK INSERT ----------\n",
    "cursor.executemany(insert_sql, records)\n",
    "conn.commit()\n",
    "\n",
    "print(f\"{cursor.rowcount} rows inserted successfully.\")\n",
    "\n",
    "cursor.close()\n",
    "conn.close()\n"
   ],
   "id": "d887bbb06f53dce9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8469 rows inserted successfully.\n"
     ]
    }
   ],
   "execution_count": 11
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
